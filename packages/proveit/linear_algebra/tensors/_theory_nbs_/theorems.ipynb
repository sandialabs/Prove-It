{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorems (or conjectures) for the theory of <a class=\"ProveItLink\" href=\"theory.ipynb\">proveit.linear_algebra.tensors</a>\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proveit\n",
    "# Prepare this notebook for defining the theorems of a theory:\n",
    "%theorems_notebook # Keep this at the top following 'import proveit'.\n",
    "\n",
    "from proveit import Function, ExprRange, IndexedVar\n",
    "from proveit import a, b, c, d, e, f, g, i, j, k, m, n, s, t, x, y, K, Q, S, U, V, W, alpha, fb\n",
    "from proveit.core_expr_types import (\n",
    "    a_1_to_i, a_1_to_m, b_1_to_j, c_1_to_k, c_1_to_n, \n",
    "    d_1_to_i, d_1_to_j, e_1_to_k, f_1_to_k, f__b_1_to_j, fj,\n",
    "    n_1_to_m, n_k,\n",
    "    A_1_to_i, B_1_to_j, C_1_to_k, U_1_to_i, V_1_to_i, W_1_to_k)\n",
    "from proveit.logic import (Implies, And, Forall, Equals, NotEquals, \n",
    "                           InSet, InClass, CartExp, SubsetEq)\n",
    "from proveit.numbers import one, Natural, NaturalPos, Add, Mult\n",
    "from proveit.linear_algebra import (VecSpaces, InnerProdSpaces, VecAdd, VecSum, VecZero,\n",
    "                                    ScalarMult, Norm, TensorProd, TensorExp)\n",
    "from proveit.linear_algebra.addition import vec_summation_b1toj_fQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%begin theorems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_is_in_tensor_prod_space = Forall(\n",
    "    K, Forall(\n",
    "        i, Forall(\n",
    "            V_1_to_i, Forall(\n",
    "                a_1_to_i, InSet(TensorProd(a_1_to_i),\n",
    "                                TensorProd(V_1_to_i)),\n",
    "                domains=[V_1_to_i]),\n",
    "            domain=VecSpaces(K)),\n",
    "        domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_of_vec_spaces_is_vec_space = Forall(\n",
    "    K, Forall(i, Forall(V_1_to_i, InClass(TensorProd(V_1_to_i),\n",
    "                                          VecSpaces(K)),\n",
    "                        domain=VecSpaces(K)),\n",
    "              domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_association = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            (i, j, k), Forall(\n",
    "                V, Forall(\n",
    "                    (a_1_to_i, b_1_to_j, c_1_to_k),\n",
    "                    Implies(\n",
    "                        InSet(TensorProd(a_1_to_i, b_1_to_j, \n",
    "                                         c_1_to_k), V),\n",
    "                        Equals(\n",
    "                            TensorProd(a_1_to_i, b_1_to_j, c_1_to_k),\n",
    "                            TensorProd(a_1_to_i, TensorProd(b_1_to_j), \n",
    "                                       c_1_to_k))\n",
    "                        .with_wrap_before_operator())\n",
    "                    .with_wrap_after_operator()).with_wrapping(),\n",
    "                domain=VecSpaces(K)).with_wrapping(),\n",
    "            domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_vec_space_association = (\n",
    "    Forall(K,\n",
    "    Forall((i, j, k),\n",
    "    Forall((A_1_to_i, B_1_to_j, C_1_to_k),\n",
    "                        Equals(\n",
    "                            TensorProd(A_1_to_i, B_1_to_j, C_1_to_k),\n",
    "                            TensorProd(A_1_to_i, TensorProd(B_1_to_j), \n",
    "                                       C_1_to_k))\n",
    "       .with_wrap_before_operator(),\n",
    "    domain=VecSpaces(K)).with_wrapping(),\n",
    "    domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_disassociation = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            (i, j, k), Forall(\n",
    "                V, Forall(\n",
    "                    (a_1_to_i, b_1_to_j, c_1_to_k),\n",
    "                    Implies(\n",
    "                        InSet(TensorProd(\n",
    "                            a_1_to_i, TensorProd(b_1_to_j),\n",
    "                            c_1_to_k), V),\n",
    "                        Equals(\n",
    "                            TensorProd(a_1_to_i, TensorProd(b_1_to_j), \n",
    "                                       c_1_to_k),\n",
    "                            TensorProd(a_1_to_i, b_1_to_j, c_1_to_k))\n",
    "                        .with_wrap_before_operator())\n",
    "                    .with_wrap_after_operator()).with_wrapping(),\n",
    "                domain=VecSpaces(K)).with_wrapping(),\n",
    "            domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_vec_space_disassociation = (\n",
    "    Forall(K,\n",
    "    Forall((i, j, k),\n",
    "    Forall((A_1_to_i, B_1_to_j, C_1_to_k),\n",
    "                        Equals(TensorProd(A_1_to_i, TensorProd(B_1_to_j), \n",
    "                                       C_1_to_k),\n",
    "                              TensorProd(A_1_to_i, B_1_to_j, C_1_to_k))\n",
    "       .with_wrap_before_operator(),\n",
    "    domain=VecSpaces(K)).with_wrapping(),\n",
    "    domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the antecedent here may be insufficient,\n",
    "# because we may not be able to infer that\n",
    "# all b_i are from same vector space\n",
    "tensor_prod_distribution_over_add = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            (i, j, k), Forall(\n",
    "                V, Forall(\n",
    "                    (a_1_to_i, b_1_to_j, c_1_to_k),\n",
    "                    Implies(\n",
    "                        InSet(TensorProd(\n",
    "                            a_1_to_i, VecAdd(b_1_to_j), \n",
    "                            c_1_to_k), V),\n",
    "                        Equals(\n",
    "                            TensorProd(a_1_to_i, VecAdd(b_1_to_j),\n",
    "                                       c_1_to_k),\n",
    "                            VecAdd(ExprRange(\n",
    "                                m, TensorProd(a_1_to_i, \n",
    "                                              IndexedVar(b, m),\n",
    "                                              c_1_to_k),\n",
    "                                one, j)))\n",
    "                        .with_wrap_after_operator())\n",
    "                    .with_wrap_after_operator()).with_wrapping(),\n",
    "                domain=VecSpaces(K)).with_wrapping(),\n",
    "             domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_distribution_over_summation = (\n",
    "    Forall(\n",
    "        (K, f, Q), Forall(\n",
    "            (i, j, k), Forall(\n",
    "                V, Forall(\n",
    "                    (a_1_to_i, c_1_to_k), \n",
    "                    Implies(\n",
    "                        Forall(b_1_to_j, InSet(TensorProd(\n",
    "                            a_1_to_i, f__b_1_to_j, \n",
    "                            c_1_to_k), V), condition=Function(Q, b_1_to_j)),\n",
    "                        Equals(\n",
    "                            TensorProd(a_1_to_i, vec_summation_b1toj_fQ, c_1_to_k),\n",
    "                            VecSum(b_1_to_j, TensorProd(a_1_to_i, f__b_1_to_j, c_1_to_k),\n",
    "                                   condition=Function(Q, b_1_to_j)))\n",
    "                        .with_wrap_before_operator())\n",
    "                    .with_wrap_after_operator()),\n",
    "                domain=VecSpaces(K)),\n",
    "             domains=(Natural, NaturalPos, Natural))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_distribution_over_summation_with_scalar_mult = (\n",
    "    Forall((K, f, Q, s),\n",
    "    Forall((i, j, k),\n",
    "    Forall(V,\n",
    "    Forall((a_1_to_i, c_1_to_k), \n",
    "        Implies(\n",
    "            Forall(b_1_to_j, InSet(TensorProd(\n",
    "                a_1_to_i, ScalarMult(Function(s, b_1_to_j), f__b_1_to_j), \n",
    "                c_1_to_k), V), condition=Function(Q, b_1_to_j)),\n",
    "            Equals(\n",
    "                TensorProd(a_1_to_i, VecSum(b_1_to_j, ScalarMult(Function(s, b_1_to_j), f__b_1_to_j) , condition=Function(Q, b_1_to_j)), c_1_to_k),\n",
    "                VecSum(b_1_to_j, ScalarMult(Function(s, b_1_to_j), TensorProd(a_1_to_i, f__b_1_to_j, c_1_to_k)),\n",
    "                       condition=Function(Q, b_1_to_j)))\n",
    "            .with_wrap_before_operator())\n",
    "        .with_wrap_after_operator()).with_wrapping(),\n",
    "    domain=VecSpaces(K)).with_wrapping(),\n",
    "    domains=(Natural, NaturalPos, Natural))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_scalar_from_tensor_prod = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            alpha, Forall(\n",
    "                (i, k), Forall(\n",
    "                    V, Forall(\n",
    "                        (a_1_to_i, b, c_1_to_k),\n",
    "                        Implies(\n",
    "                            InSet(TensorProd(\n",
    "                                a_1_to_i, ScalarMult(alpha, b), \n",
    "                                c_1_to_k), V),\n",
    "                            Equals(\n",
    "                                TensorProd(a_1_to_i, \n",
    "                                           ScalarMult(alpha, b), \n",
    "                                           c_1_to_k),\n",
    "                                ScalarMult(alpha, \n",
    "                                           TensorProd(a_1_to_i,\n",
    "                                                      b, c_1_to_k)))\n",
    "                            .with_wrap_before_operator())\n",
    "                        .with_wrap_after_operator()).with_wrapping(),\n",
    "                    domain=VecSpaces(K)),\n",
    "                domain=Natural),\n",
    "            domain=K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_vec_on_both_sides_of_equality = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            (i, k), Forall(\n",
    "                (U_1_to_i, V, W_1_to_k), Forall(\n",
    "                    (a_1_to_i, c_1_to_k, d_1_to_i, f_1_to_k), Forall(\n",
    "                        (b, e), \n",
    "                        Implies(Equals(TensorProd(a_1_to_i, b, c_1_to_k),\n",
    "                                       TensorProd(d_1_to_i, e, f_1_to_k))\n",
    "                                .with_wrap_after_operator(),\n",
    "                                Equals(TensorProd(a_1_to_i, c_1_to_k), \n",
    "                                       TensorProd(d_1_to_i, f_1_to_k))\n",
    "                                .with_wrap_after_operator())\n",
    "                        .with_wrap_after_operator(),\n",
    "                        domain=V, conditions=[\n",
    "                            Equals(b, e),\n",
    "                            NotEquals(b, VecZero(V))]),\n",
    "                    domains=(U_1_to_i, W_1_to_k, U_1_to_i, W_1_to_k)).with_wrapping(),\n",
    "                domain=VecSpaces(K)).with_wrapping(),\n",
    "             domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_vec_on_both_sides_of_equality = (\n",
    "    Forall(\n",
    "        K, Forall(\n",
    "            (i, k), Forall(\n",
    "                (U_1_to_i, V, W_1_to_k), Forall(\n",
    "                    (a_1_to_i, c_1_to_k, d_1_to_i, e_1_to_k), Forall(\n",
    "                        b, \n",
    "                        Implies(Equals(TensorProd(a_1_to_i, c_1_to_k),\n",
    "                                       TensorProd(d_1_to_i, e_1_to_k))\n",
    "                                .with_wrap_after_operator(),\n",
    "                                Equals(TensorProd(a_1_to_i, b, c_1_to_k), \n",
    "                                       TensorProd(d_1_to_i, b, e_1_to_k))\n",
    "                               .with_wrap_after_operator())\n",
    "                        .with_wrap_after_operator(),\n",
    "                        domain=V),\n",
    "                    domains=(U_1_to_i, W_1_to_k, U_1_to_i, W_1_to_k)).with_wrapping(),\n",
    "                domain=VecSpaces(K)).with_wrapping(),\n",
    "             domain=Natural)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_prod_of_cart_exps_within_cart_exp = Forall(\n",
    "    K, Forall(m, Forall(n_1_to_m, SubsetEq(TensorProd(ExprRange(k, CartExp(K, n_k), one, m)),\n",
    "                                           CartExp(K, Mult(n_1_to_m))),\n",
    "                        domain=NaturalPos),\n",
    "              domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_exp_inclusion = Forall(\n",
    "    K, Forall(\n",
    "        n, Forall(V, SubsetEq(TensorExp(V, n), CartExp(V, n)),\n",
    "                       domain=VecSpaces(K)),\n",
    "        domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_exp_of_cart_exp_inclusion = Forall(\n",
    "    K, Forall(\n",
    "        (m, n), Forall(V, SubsetEq(TensorExp(CartExp(V, m), n), CartExp(V, Mult(m, n))),\n",
    "                       domain=VecSpaces(K)),\n",
    "        domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_of_tensor_prod = Forall(\n",
    "    K, Forall(\n",
    "        i, Forall(\n",
    "            V_1_to_i, Forall(a_1_to_i, Equals(Norm(TensorProd(a_1_to_i)),\n",
    "                                       Mult(ExprRange(k, Norm(IndexedVar(a, k)),\n",
    "                                                      one, i))),\n",
    "                      domains=[V_1_to_i]).with_wrapping(),\n",
    "            domain=InnerProdSpaces(K)).with_wrapping(),\n",
    "        domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_preserving_tensor_prod = Forall(\n",
    "    K, Forall(\n",
    "        i, Forall(\n",
    "            V_1_to_i, Forall(\n",
    "                a_1_to_i, Equals(Norm(TensorProd(a_1_to_i)), one),\n",
    "                domains=[V_1_to_i],\n",
    "                condition=And(ExprRange(k, Equals(Norm(IndexedVar(a, k)),\n",
    "                                                  one),\n",
    "                                        one, i))).with_wrapping(),\n",
    "            domain=InnerProdSpaces(K)).with_wrapping(),\n",
    "        domain=NaturalPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%end theorems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
