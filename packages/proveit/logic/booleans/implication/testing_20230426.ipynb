{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proveit\n",
    "from proveit import A, B\n",
    "from proveit import defaults\n",
    "from proveit.logic import Implies\n",
    "from proveit.logic.booleans.conjunction import and_t_t, left_from_and\n",
    "from proveit import Database\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "%begin testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Modus Ponens_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick and simple testing involving the most basic _modus ponens_ judgment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result = B.prove(assumptions=[Implies(A, B), A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result._core_info == ('Variable', 'B', 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp_result.assumptions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions[0]._core_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result._sub_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions[0]._sub_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_literal_obj = temp_result.assumptions[0]._sub_expressions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions[0]._sub_expressions[0]._core_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.expr.string_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp_result.assumptions[0]) == proveit.logic.booleans.implication.implies.Implies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some review about lists as “subsets” of other lists …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_01, list_02, list_03, list_04 = (\n",
    "    [Implies(A, B), A], [Implies(A, B)], [A], [B])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For “comparable” list items, we can utilize `<` and `<=`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_02 < list_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But our situation is more complicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_03 < list_01\n",
    "except TypeError as te:\n",
    "    print(\"Type Error: {}\".format(te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can convert to set and use issubset(), which should work for us since any repeated list elements can be safely eliminated anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list_02).issubset(list_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list_03).issubset(list_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list_04).issubset(list_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing lists of theorems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"Theory\" for the current working directory \n",
    "temp_theory = proveit.Theory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp_theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"Theory\" for a specific working directory \n",
    "temp_theory_2 = proveit.Theory('../../../numbers') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we need to find the theory for another package we're not explicitly told where we current are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "temp_notebook_path = os.getcwd()\n",
    "print(temp_notebook_path)\n",
    "temp_notebook_path.find('proveit/')\n",
    "proveit_path = temp_notebook_path[:temp_notebook_path.find('proveit/')+len('proveit/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"Theory\" for a specific working directory using explicit path?\n",
    "temp_theory_3 = proveit.Theory(proveit_path + 'logic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_theory_3.get_common_expression_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_theory.get_axiom_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_theory_2.get_axiom_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_theory.get_axiom('implies_t_f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_theory.get_axiom('implies_t_f').proven_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01 = temp_theory.get_axiom('implies_t_f').proven_truth.expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.expr_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.expr_info()._getEnumeratedExpressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.formatted('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.core_info()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_expr_01.sub_expr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in example_expr_01.sub_expr_iter():\n",
    "    display(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _proveItObjUniqueRep_alt(prove_it_object):\n",
    "    '''\n",
    "    Generate a unique representation string for the given Prove-It\n",
    "    object that is dependent upon the style.\n",
    "    Borrowed from _theory_storage.py and modified accordingly.\n",
    "    So this is kind of pretend-ish, because it's not at all clear\n",
    "    what function should be being fed to the _generate_unique_rep()\n",
    "    method in the return line.\n",
    "    '''\n",
    "    from proveit import Expression, Judgment, Proof\n",
    "    prefix = None\n",
    "    if isinstance(prove_it_object, Expression):\n",
    "        prefix = ''  # No prefix for Expressions\n",
    "    elif isinstance(prove_it_object, Judgment):\n",
    "        # prefix to indicate that it is a Judgment\n",
    "        prefix = 'Judgment:'\n",
    "    elif isinstance(prove_it_object, Proof):\n",
    "        prefix = 'Proof:'  # prefix to indicate that it is a Proof\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Strorage only implemented for Expressions,'\n",
    "            'Judgments, and Proofs')\n",
    "    # Generate a unique representation using Prove-It object ids for\n",
    "    # this storage to represent other referenced Prove-It objects.\n",
    "#     return prefix + prove_it_object._generate_unique_rep(\n",
    "#         self._prove_it_storage_id)\n",
    "    return prefix + prove_it_object._generate_unique_rep(lambda expr: hex(expr._style_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_unique_rep(unique_rep):\n",
    "    '''\n",
    "    parse an Expression's unique_rep generated by the\n",
    "    _proveItObjUniqueRep_alt() method.\n",
    "    Borrowed from expr.py (Expression class) and modified accordingly.\n",
    "    So this is kind of pretend-ish.\n",
    "    '''\n",
    "    sub_expr_info, expr_class_str, core_info_str, style_str = \\\n",
    "        unique_rep.split(';')\n",
    "    core_info = [_ for _ in core_info_str.split(',') if _ != '']\n",
    "    style_pairs = [_ for _ in style_str.split(',') if _ != '']\n",
    "    style_dict = dict(style_pair.split(':') for style_pair in style_pairs)\n",
    "    sub_expr_refs = [_ for _ in sub_expr_info.split(',') if _ != '']\n",
    "    return expr_class_str, core_info, style_dict, sub_expr_refs\n",
    "\n",
    "# our unique rep: Judgment:0x372c6581ceedec03;[-0x44e71e006250fd8b,-0x5857f38715f61ec1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def getSuperClassNames(anObject):\n",
    "    superClassNames = []\n",
    "    if (inspect.isclass(anObject) == False): anObject = anObject.__class__\n",
    "    classes = inspect.getmro(anObject)\n",
    "    for cl in classes:\n",
    "        s = str(cl).replace('\\'', '').replace('>', '')\n",
    "        if (\"__main__.\" in s): superClassNames.append(s.split('.', 1)[1])\n",
    "    clName = str(anObject.__name__)\n",
    "    if (clName in superClassNames): superClassNames.remove(clName)\n",
    "    if (len(superClassNames) == 0): superClassNames = None\n",
    "    return superClassNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proveit import Expression, Judgment\n",
    "\n",
    "from proveit import Judgment\n",
    "import inspect\n",
    "import hashlib\n",
    "\n",
    "print(\"For temp_result: {}:\".format(temp_result))\n",
    "print(\"    assumptions: {}\".format(temp_result.assumptions))\n",
    "print(\"    proof().proven_truth: {}\".format(temp_result.proof().proven_truth))\n",
    "print(\"    proof().step_type(): {}\".format(temp_result.proof().step_type()))\n",
    "print(\"    core_info(): {}\".format(temp_result.core_info()))\n",
    "print(\"type(temp_result): {}\".format(type(temp_result)))\n",
    "print(\"temp_result.__class__: {}\".format(temp_result.__class__))\n",
    "print(\"temp_result.__class__.__name__: {}\".format(temp_result.__class__.__name__))\n",
    "print(temp_result)\n",
    "example_str = temp_result.string()\n",
    "print(\"type(example_str) = {}\".format(type(example_str)))\n",
    "\n",
    "# test the _proveItObjUniqueRep_alt method def'd above\n",
    "temp_result_unique_rep = _proveItObjUniqueRep_alt(temp_result)\n",
    "print(\"our unique rep: {}\".format(temp_result_unique_rep))\n",
    "\n",
    "# test Prove-It's Expression._parse_unique_rep() method\n",
    "# (expr_class_str, core_info, style_dict, sub_expr_refs) = \\\n",
    "#                     Expression._parse_unique_rep(temp_result_unique_rep)\n",
    "\n",
    "# then get a hash representation of that unique representation\n",
    "# (taken from a line in TheoryFolderStorage._retrieve() method)\n",
    "rep_hash = hashlib.sha1(temp_result_unique_rep.encode('utf-8')).hexdigest()\n",
    "print(\"our unique rep of the unique rep: {}\".format(rep_hash))\n",
    "\n",
    "# print(\"SuperClasses: {}\".format(getSuperClassNames(temp_result)))\n",
    "temp_result_type = temp_result.__class__.__name__\n",
    "# _proveItObjUniqueRep_alt(temp_result_unique_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proveit import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While() Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while(i<10):\n",
    "    if i%2==0:\n",
    "        print(i)\n",
    "        i += 2\n",
    "        print(i)\n",
    "        continue\n",
    "    print(\"i = {}\".format(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxn_with_kwargs(**kwargs):\n",
    "    print(kwargs)\n",
    "    print(enumerate(kwargs.items()))\n",
    "    temp_str = \"\"\n",
    "    for i,(k,v) in enumerate(kwargs.items()):\n",
    "            print(\"({0}) {1} = {2}\".format(i, k, v))\n",
    "            if isinstance(v, str):\n",
    "                v = \"\\'\" + str(v) + \"\\'\"\n",
    "            if i==0:\n",
    "                temp_str = \"SELECT * WHERE ({0}={1}\".format(k, v)\n",
    "            else:\n",
    "                temp_str = temp_str + \" AND {0} = {1}\".format(k, v)\n",
    "    temp_str = temp_str + \")\"\n",
    "    print(temp_str)\n",
    "    if len(kwargs)==0:\n",
    "        print(\"No kwargs supplied!\")\n",
    "    for k in kwargs.keys():\n",
    "        print(\"k = {}\".format(k))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory Package and Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Theory for the current notebook location\n",
    "temp_theory = proveit.Theory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then get that theory's database if it exists\n",
    "# and show the content of the judgment and expression tables\n",
    "if hasattr(temp_theory._storage, 'pkg_database'):\n",
    "    temp_database = temp_theory._storage.pkg_database\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  common table                                                                      *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, name, expr, string_format, latex_format                                       *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('common'))\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  axiom table                                                                       *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, path_name, name, judgment, string_format, latex_format                        *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('axiom'))\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  theorem table                                                                     *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, path_name, name, judgment, string_format, latex_format                        *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('theorem'))\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  judgment table                                                                    *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, expr, assumptions, num_lit_gens, string_format, latex_format                  *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('judgment'))\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  expression table                                                                  *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, subexpressions, class_path, core_info, style_str, string_format, latex_format *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('expression'))\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  proof_step table                                                                  *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    print(\"*  id, type, path_name, name, judgment_id, reqs, eq_reqs, instantiations,            *\")\n",
    "    print(\"*  string_format, latex_format                                                       *\")\n",
    "    print(\"* ================================================================================== *\")\n",
    "    display(temp_database.fetch_all('proof_step'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_database.clear_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_proof_steps = temp_database.fetch_all('proof_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_step_items = [\" #         \", \" step id   \", \" step type \", \" path name \", \" name      \", \" judgment  \",\n",
    "                    \" req's     \", \" eq req's  \",\" instant's \", \" string    \", \" latex     \"]\n",
    "print(\"proof_step table entries\")\n",
    "for step in some_proof_steps:\n",
    "    for i in range(len(step)):\n",
    "        if i == 0:\n",
    "            print(\" ========== \")\n",
    "        else:\n",
    "            print(\"{}: {}\".format(proof_step_items[i], step[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_judgments = temp_database.fetch_all('judgment')\n",
    "for judgment in some_judgments:\n",
    "    print(\" ========== \")\n",
    "    print(\" judgment id:  {}\".format(judgment[1]))\n",
    "    print(\" expr:         {}\".format(judgment[2]))\n",
    "    print(\" assumptions:  {}\".format(judgment[3]))\n",
    "    print(\" num lit gens: {}\".format(judgment[4]))\n",
    "    print(\" string:       {}\".format(judgment[5]))\n",
    "    print(\" latex:        {}\".format(judgment[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_expressions = temp_database.fetch_all('expression')\n",
    "for expression in some_expressions:\n",
    "    print(\" ========== \")\n",
    "    print(\" expr id:    {}\".format(expression[1]))\n",
    "    print(\" sub exprs:  {}\".format(expression[2]))\n",
    "    print(\" class path: {}\".format(expression[3]))\n",
    "    print(\" core info:  {}\".format(expression[4]))\n",
    "    print(\" style str:  {}\".format(expression[5]))\n",
    "    print(\" string:     {}\".format(expression[6]))\n",
    "    print(\" latex:      {}\".format(expression[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking a modus ponens proof step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISSUE: expressions (and thus sub-expressions, which are just more expressions) can (and often will) be located in other package databases. At least two ways to deal with this:</br>\n",
    "<ol>\n",
    "  <li>During initial importing of such items, simply put them (where, exactly?) in the current package database;</li>\n",
    "  <li>Let them live in their original package database, but then be on the lookout for this when getting expression ids; when obtaining expression ids, will need to check for things like 'a.b.123' instead of just '123'.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modus_ponens_proof_step_id = temp_database.fetch_all('proof_step')[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "temp_notebook_path = os.getcwd()\n",
    "print(temp_notebook_path)\n",
    "temp_notebook_path.find('proveit/')\n",
    "proveit_path = temp_notebook_path[:temp_notebook_path.find('proveit/')+len('proveit/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proof_check(modus_ponens_proof_step_id):\n",
    "    '''\n",
    "    Recursively check all steps in the proof tree rooted at the proof step\n",
    "    with hash id proof_step_id.\n",
    "    Currently only addresses for modus ponens proof steps.\n",
    "    Currently contains lots of print statements for manual checking.\n",
    "    '''\n",
    "    steps_to_check = [modus_ponens_proof_step_id]\n",
    "    notebook_path = os.getcwd()\n",
    "    proveit_path = notebook_path[: notebook_path.find('/proveit/') + len('/proveit/')]\n",
    "    print(f\"proveit_path = {proveit_path}\\n\")\n",
    "    \n",
    "    while len(steps_to_check) > 0:\n",
    "        current_step_id = steps_to_check.pop();\n",
    "        if not temp_database.check_for_record('proof_step', {'id':current_step_id}):\n",
    "            raise ValueError(f\"proof_step table record {current_step_id} not found!\")\n",
    "        # if record exists, continue\n",
    "        current_step_info = temp_database.retrieve_records_as_dictionaries('proof_step', {'id':current_step_id})[0]\n",
    "        print(f\"current_step_info:\\n\")\n",
    "        for key, value in current_step_info.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        print()\n",
    "        step_type = current_step_info['type'];\n",
    "\n",
    "        # ASSUMPTION step\n",
    "        if step_type == 'assumption':\n",
    "            print(f\"    assumption proof step! (skipping to next step)\\n\\n\")\n",
    "\n",
    "        # MODUS PONENS step\n",
    "        if step_type == 'modus ponens':\n",
    "            # grab the 'requirements' for the modus ponens step; should be a list of 2 hash ids\n",
    "            mp_step_req_ids = current_step_info['requirements'].strip('][').split(',')\n",
    "            if len(mp_step_req_ids) != 2:\n",
    "                # for now, raise an error; but more generally, should we continue?\n",
    "                raise ValueError(\"Insufficient support for modus ponen step.\")\n",
    "            print(\"    modus ponens requirements are:\")\n",
    "            for req_id in mp_step_req_ids:\n",
    "                print(f\"        {req_id}\")\n",
    "            print()\n",
    "            # add each of those requirements to the list of steps to check\n",
    "            steps_to_check =  steps_to_check + mp_step_req_ids\n",
    "            print(\"    steps_to_check are now:\")\n",
    "            for step in steps_to_check:\n",
    "                print(f\"        {step}\")\n",
    "            print()\n",
    "\n",
    "            # obtain proof_step info for each of the requirements\n",
    "            requirement_step_info = []\n",
    "            for id in mp_step_req_ids:\n",
    "                requirement_step_info.append(temp_database.retrieve_records_as_dictionaries('proof_step', {'id':id})[0])\n",
    "\n",
    "            # get corresponding judgment ids\n",
    "            mp_judgment_id = current_step_info['judgment']\n",
    "            print(f\"    mp_judgment_id: {mp_judgment_id}\")\n",
    "            requirement_judgment_ids = []\n",
    "            for req_step in requirement_step_info:\n",
    "                requirement_judgment_ids.append(req_step['judgment'])\n",
    "            for i, judgment_id in enumerate(requirement_judgment_ids):\n",
    "                print(f\"    requirement judgment {i}: {judgment_id}\")\n",
    "\n",
    "            # get corresponding judgment table entries\n",
    "            # future: could use a single list of these entries instead of one record and a list of 2 records\n",
    "            # that would allow us to compact throughout\n",
    "            mp_judgment_info = temp_database.retrieve_records_as_dictionaries('judgment', {'id':mp_judgment_id})[0]\n",
    "            print(\"\\n    mp_judgment_info:\\n\")\n",
    "            for key, value in mp_judgment_info.items():\n",
    "                print(f\"        {key}: {value}\")\n",
    "            requirement_judgment_info = []\n",
    "            for id in requirement_judgment_ids:\n",
    "                requirement_judgment_info.append(temp_database.retrieve_records_as_dictionaries('judgment', {'id':id})[0])\n",
    "            print(\"\\n    requirement judgments info:\\n\")\n",
    "            for judgment_info in requirement_judgment_info:\n",
    "                for key, value in judgment_info.items():\n",
    "                    print(f\"        {key}: {value}\")\n",
    "                print()\n",
    "\n",
    "            # get corresponding expression ids (ids for the rhs of the judgments)\n",
    "            # warning: these may now refer to other theory packages, so we need to eventually catch and use that info\n",
    "            expression_ids = []\n",
    "            expression_ids.append(mp_judgment_info['expression'])\n",
    "            for judgment_info in requirement_judgment_info:\n",
    "                expression_ids.append(judgment_info['expression'])\n",
    "            print(f\"\\n    expression ids are:\\n\")\n",
    "            for expr_id in expression_ids:\n",
    "                print(f\"        {expr_id}\")\n",
    "\n",
    "            # get corresponding expression table info\n",
    "            expression_info = []\n",
    "            for expr_id in expression_ids:\n",
    "                if '.' not in expr_id:\n",
    "                    expression_info.append(temp_database.retrieve_records_as_dictionaries('expression', {'id':expr_id})[0])\n",
    "                else:\n",
    "                    # expr_id refers to database in another package; oh joy\n",
    "                    split_id = expr_id.split('.')\n",
    "                    additional_path_spec = ''\n",
    "                    for i in range(1,len(split_id)-2):\n",
    "                        additional_path_spec += split_id[i] + '/'\n",
    "                    print(f\"additional_path_spec = {additional_path_spec}\")\n",
    "                    temp_path_spec = proveit_path + additional_path_spec\n",
    "                    print(f\"temp_path_spec = {temp_path_spec}\")\n",
    "                    another_temp_theory = proveit.Theory(temp_path_spec)\n",
    "                    if not hasattr(another_temp_theory._storage, 'pkg_database'):\n",
    "                        raise ValueError(\"No such database :o(\")\n",
    "                    another_temp_database = another_temp_theory._storage.pkg_database\n",
    "                    temp_result = another_temp_database.retrieve_records_as_dictionaries(split_id[-2], {'id':split_id[-1]})\n",
    "                    print(f\"temp_result = {temp_result}\")\n",
    "                    expression_info.append(another_temp_database.retrieve_records_as_dictionaries(split_id[-2], {'id':split_id[-1]})[0])\n",
    "            print(f\"\\n    expression info:\\n\")\n",
    "            for item in expression_info:\n",
    "                for key, value in item.items():\n",
    "                    print(f\"        {key}: {value}\")\n",
    "                print()\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "            # need to figure out which of the requirements is the implication and\n",
    "            # which is the antecedent of the other. The complication: both requirements may be implications.\n",
    "            # so we need to go to the expression table level\n",
    "            # req_01_expression_id = \n",
    "\n",
    "            print()\n",
    "\n",
    "    print(f\"\\n===== Done processing proof steps! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying this another way first, experimenting with just tracking down the expr `Expression` and assumption `Expressions`for the modus ponens proof step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proof_check_02(modus_ponens_proof_step_id):\n",
    "    '''\n",
    "    Recursively check all steps in the proof tree rooted at the proof step\n",
    "    with hash id proof_step_id. Well, eventually.\n",
    "    Currently assumes that the proof step id supplied will be found in the\n",
    "    current theory package database. Future versions might allow us to \n",
    "    feed in alternative theory package locations for more generality.\n",
    "    Currently only addresses for modus ponens proof steps.\n",
    "    Currently contains lots of print statements for manual checking.\n",
    "    '''\n",
    "    steps_to_check = [modus_ponens_proof_step_id]\n",
    "\n",
    "    # determine path for possible use in other theory package databases\n",
    "    # when tracking down eventual Expression(s)\n",
    "    notebook_path = os.getcwd()\n",
    "    proveit_path = notebook_path[: notebook_path.find('/proveit/') + len('/proveit/')]\n",
    "    print(f\"proveit_path = {proveit_path}\\n\")\n",
    "    \n",
    "    while len(steps_to_check) > 0:\n",
    "        current_step_id = steps_to_check.pop();\n",
    "        if not temp_database.check_for_record('proof_step', {'id':current_step_id}):\n",
    "            raise ValueError(f\"proof_step table record {current_step_id} not found!\")\n",
    "        # if record exists, retrieve all details of proof step from proof_step table\n",
    "        current_step_info = temp_database.retrieve_records_as_dictionaries('proof_step', {'id':current_step_id})[0]\n",
    "\n",
    "        # ===== FOR TESTING: print the current step information ===== #\n",
    "        print(f\"current_step_info:\\n\")\n",
    "        for key, value in current_step_info.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        print()\n",
    "        step_type = current_step_info['type'];\n",
    "\n",
    "        # Non-MODUS PONENS step\n",
    "        if step_type != 'modus ponens':\n",
    "            print(f\"    Non-modus-ponens proof step! (skipping to next step)\\n\\n\")\n",
    "\n",
    "        # MODUS PONENS step\n",
    "        if step_type == 'modus ponens':\n",
    "            # grab the 'requirements' for the modus ponens step; should be a list of 2 hash ids\n",
    "            mp_step_req_ids = current_step_info['requirements'].strip('][').split(',')\n",
    "            if len(mp_step_req_ids) != 2:\n",
    "                # for now, raise an error; but more generally, should we continue?\n",
    "                raise ValueError(\"Insufficient support for modus ponen step.\")\n",
    "            print(\"PASSED requirements numerosity check!\")\n",
    "            # ===== FOR TESTING: print the requirement proof step ids ===== #\n",
    "            print(\"    modus ponens requirements are:\")\n",
    "            for req_id in mp_step_req_ids:\n",
    "                print(f\"        {req_id}\")\n",
    "            print()\n",
    "            # ===== END TESTING ===== #\n",
    "            \n",
    "            # add each of those requirements to the list of steps to check\n",
    "            steps_to_check +=  mp_step_req_ids\n",
    "\n",
    "            # ===== FOR TESTING: print the steps_to_check list ===== #\n",
    "            print(\"    steps_to_check are now:\")\n",
    "            for step in steps_to_check:\n",
    "                print(f\"        {step}\")\n",
    "            print()\n",
    "            # ===== END TESTING ===== #\n",
    "\n",
    "            # obtain proof_step info for each of the requirements\n",
    "            requirement_step_info = []\n",
    "            for id in mp_step_req_ids:\n",
    "                requirement_step_info.append(temp_database.retrieve_records_as_dictionaries('proof_step', {'id':id})[0])\n",
    "\n",
    "            # get corresponding judgment ids\n",
    "            mp_judgment_id = current_step_info['judgment']\n",
    "            # ===== FOR TESTING: print the judgment id mp proof step ===== #\n",
    "            print(f\"    mp_judgment_id: {mp_judgment_id}\")\n",
    "            # ===== END TESTING ===== #\n",
    "            requirement_judgment_ids = []\n",
    "            for req_step in requirement_step_info:\n",
    "                requirement_judgment_ids.append(req_step['judgment'])\n",
    "            # ===== FOR TESTING: print the judgment ids for the requirements ===== #\n",
    "            for i, judgment_id in enumerate(requirement_judgment_ids):\n",
    "                print(f\"    requirement judgment {i}: {judgment_id}\")\n",
    "            # ===== END TESTING ===== #\n",
    "\n",
    "            # Get corresponding judgment table entries.\n",
    "            # We then use each judgment entry to get the expression ids associated with:\n",
    "            # (1) the assumptions (LHS of the turnstile) and \n",
    "            # (2) judgment expression (RHS of the turnstile).\n",
    "            # future: could use a single list of these entries instead of one record and a list of 2 records\n",
    "            # that would allow us to compact throughout\n",
    "            mp_judgment_info = temp_database.retrieve_records_as_dictionaries('judgment', {'id':mp_judgment_id})[0]\n",
    "            print(\"\\n    mp_judgment_info:\\n\")\n",
    "            for key, value in mp_judgment_info.items():\n",
    "                print(f\"        {key}: {value}\")\n",
    "            requirement_judgment_info = []\n",
    "            for id in requirement_judgment_ids:\n",
    "                requirement_judgment_info.append(temp_database.retrieve_records_as_dictionaries('judgment', {'id':id})[0])\n",
    "            print(\"\\n    requirement judgments info:\\n\")\n",
    "            for judgment_info in requirement_judgment_info:\n",
    "                for key, value in judgment_info.items():\n",
    "                    print(f\"        {key}: {value}\")\n",
    "                print()\n",
    "\n",
    "            # Get each judgment's assumptions ids. The assumption ids for the requirements should be\n",
    "            # elements of the set of assumption ids found in the mp judgment step.\n",
    "            # That membership requirement constitutes our 2nd check on validity.\n",
    "            mp_judgment_assumption_ids = mp_judgment_info['assumptions'].strip('][').split(',')\n",
    "            # ===== FOR TESTING: print the mp judgment's assumption ids ===== #\n",
    "            print(\"    mp judgment assumption ids:\")\n",
    "            for assumption_id in mp_judgment_assumption_ids:\n",
    "                print(f\"        {assumption_id}\")\n",
    "            print()\n",
    "            # ===== END TESTING ===== #\n",
    "            requirement_judgment_assumption_ids = []\n",
    "            for requirement_judgment in requirement_judgment_info:\n",
    "                temp_assumption_ids = requirement_judgment['assumptions'].strip('][').split(',')\n",
    "                requirement_judgment_assumption_ids.append(temp_assumption_ids)\n",
    "            # ===== FOR TESTING: print the requirement judgment's assumption ids ===== #\n",
    "            print(\"    requirement judgment assumption ids:\")\n",
    "            for assumption_set in requirement_judgment_assumption_ids:\n",
    "                for assumption_id in assumption_set:\n",
    "                    print(f\"        {assumption_id}\")\n",
    "                print(\"        ==========\")\n",
    "            print()\n",
    "            # ===== END TESTING ===== #\n",
    "            for assumption_set in requirement_judgment_assumption_ids:\n",
    "                if not set(assumption_set).issubset(set(mp_judgment_assumption_ids)):\n",
    "                    raise ValueError(\"Requirement assumptions not a subset of MP Judgment assumptions!\")\n",
    "            print(\"PASSED assumptions subset check!\")\n",
    "            \n",
    "            # get corresponding expression ids (ids for the rhs of the judgments)\n",
    "            # warning: these may now refer to other theory packages, so we may need to eventually catch and use that info\n",
    "            expression_ids = []\n",
    "            expression_ids.append(mp_judgment_info['expression'])\n",
    "            for judgment_info in requirement_judgment_info:\n",
    "                expression_ids.append(judgment_info['expression'])\n",
    "            print(f\"\\n    expression ids are:\\n\")\n",
    "            for expr_id in expression_ids:\n",
    "                print(f\"        {expr_id}\")\n",
    "\n",
    "            # get corresponding expression table info\n",
    "            expression_info = []\n",
    "            for expr_id in expression_ids:\n",
    "                if '.' not in expr_id:\n",
    "                    expression_info.append(temp_database.retrieve_records_as_dictionaries('expression', {'id':expr_id})[0])\n",
    "                else:\n",
    "                    # expr_id refers to database in another package; oh joy\n",
    "                    split_id = expr_id.split('.')\n",
    "                    additional_path_spec = ''\n",
    "                    for i in range(1,len(split_id)-2):\n",
    "                        additional_path_spec += split_id[i] + '/'\n",
    "                    print(f\"additional_path_spec = {additional_path_spec}\")\n",
    "                    temp_path_spec = proveit_path + additional_path_spec\n",
    "                    print(f\"temp_path_spec = {temp_path_spec}\")\n",
    "                    another_temp_theory = proveit.Theory(temp_path_spec)\n",
    "                    if not hasattr(another_temp_theory._storage, 'pkg_database'):\n",
    "                        raise ValueError(\"No such database :o(\")\n",
    "                    another_temp_database = another_temp_theory._storage.pkg_database\n",
    "                    temp_result = another_temp_database.retrieve_records_as_dictionaries(split_id[-2], {'id':split_id[-1]})\n",
    "                    print(f\"temp_result = {temp_result}\")\n",
    "                    expression_info.append(another_temp_database.retrieve_records_as_dictionaries(split_id[-2], {'id':split_id[-1]})[0])\n",
    "            print(f\"\\n    expression info:\\n\")\n",
    "            for item in expression_info:\n",
    "                for key, value in item.items():\n",
    "                    print(f\"        {key}: {value}\")\n",
    "                print()\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "            # need to figure out which of the requirements is the implication and\n",
    "            # which is the antecedent of the other. The complication: both requirements may be implications.\n",
    "            # so we need to go to the expression table level\n",
    "            # req_01_expression_id = \n",
    "\n",
    "            print()\n",
    "\n",
    "    print(f\"\\n===== Done processing proof steps! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_proveit_theory = proveit.Theory('/Users/warrencraft/Desktop/Prove-It/packages/proveit/')\n",
    "if not hasattr(temp_proveit_theory._storage, 'pkg_database'):\n",
    "    raise ValueError(\"No such database :o(\")\n",
    "temp_proveit_database = temp_proveit_theory._storage.pkg_database\n",
    "temp_common_entries = temp_proveit_database.retrieve_records_as_dictionaries('common')\n",
    "temp_expression_entries = temp_proveit_database.retrieve_records_as_dictionaries('expression')\n",
    "print(\"COMMON\\n\")\n",
    "for entry in temp_common_entries:\n",
    "    print(\"==========\")\n",
    "    for key, value in entry.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "print(\"\\nEXPRESSION\\n\")\n",
    "for entry in temp_expression_entries:\n",
    "    print(\"==========\")\n",
    "    for key, value in entry.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_check_02(modus_ponens_proof_step_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_database.check_for_record('proof_step', {'id':'20b7eda420dd18b82917d5b2814aed1ac49439ac0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_database.check_for_record('proof_step', {'id':'20b7eda420dd18b82917d5b2814aed1ac49439ac1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_database.check_for_record('expression', {'id':'c5b8d4361f69ce50a6ce805adc313353b29f07ec0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.assumptions[0]._sub_expressions[1]._sub_expressions[0].latex_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.string_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result.latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_result.latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick test for obtaining a table's attributes and associated types, retrieved as a set of tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_database._get_table_attributes_and_types('common')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists and Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list_as_string_01 = \"[1, 2, 75, 45]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string list of int to list of ints\n",
    "eval(temp_list_as_string_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list_as_string_02 = \"[abc, 09aef324, 1234]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string to list (of strings)\n",
    "res = temp_list_as_string_02.strip('][').split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list_as_string_03 = \"09aef324,49bf3245,98cd76d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string to list (of strings)\n",
    "res = temp_list_as_string_03.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'proveit.logic'in 'proveit.logic.booleans.implication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'proveit.logic.bool' in 'proveit.logic.booleans.implication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_t_t.string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(and_t_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_t_t.as_theorem_or_axiom()._meaning_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing unique_reps of Axioms, Theorem, Proofs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting an Axiom's unique_rep string to other pieces\n",
    "axiom_str_example = (\n",
    "    'Proof:axiom_proveit.logic.booleans.conjunction.and_t_f:[14d696b7b1cf4d94dab325a7dc84c820f0a67c200];[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axiom_str_example.split(';')[0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axiom_str_example.split(';')[0].split(':')[1].split('_', 1)[1].rsplit('.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axiom_str_example.split(';')[0].split(':')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axiom_str_example.split(';')[0].split(':')[2].strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_unique_rep_str_example = (\n",
    "    'Proof:modus ponens:[09daae6ead570ebb0f98c95e8101b99ed2ac86710];[8c0238761a1355ce4d5bf4c8168e3774740cdf840,20b7eda420dd18b82917d5b2814aed1ac49439ac0]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the proof type\n",
    "proof_unique_rep_str_example.split(\";\")[0].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the proof's judgment id\n",
    "proof_unique_rep_str_example.split(\";\")[0].split(\":\")[2].strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the proof's list of requirements\n",
    "# notice that in the current form, we don't which table holds these requirements,\n",
    "# although we (implicitly) know which pkg_database.db file to search for each\n",
    "proof_unique_rep_str_example.split(\";\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proveit import Proof\n",
    "Proof._extractReferencedObjIds(proof_unique_rep_str_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries (as a possible return for parsing a unique_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'obj':'Proof', 'type':'modus_ponens', 'judgment_id':'abc123', 'dict':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict['obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_dict['dict']==None:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick testing of a method to ensure congruence of keys and values when then used in separate lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although current Python 3 now guarantees that the order of keys and values produced will be congruent, a safe way for producing the congruence without assuming such congruence would be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, v = zip(*test_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in k:\n",
    "    print(f'item = {item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing with the `Database._parse_unique_rep()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proveit import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database._parse_unique_rep(proof_unique_rep_str_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_unique_rep_str_example_02 = 'Proof:instantiation:{proveit.common.09585084922504426caf1db2ff588a23a0932a960:proveit.numbers.number_sets.natural_numbers.common.8b7c321957f52ed3b05b36af612eeae4fa4783bc0,proveit.common.a9162d1c3cc0470c02e5daf414500903a7a419230:proveit.numbers.number_sets.integers.common.e6b4e90f9467053e055a4fd2f735c0bb79cb79300,proveit.common.a0d9d672aa5e272d907247690c152cc2c6daafb70:proveit.numbers.numerals.common.af4aab8a07465db063742696e006d04670f30cf10}[da20b31afeaf4605a1640e59551974583346a5110];[proveit.logic.sets.inclusion.theorems.2235dee58a3fecd7484ea00ab222055c7e10c0220,proveit.numbers.number_sets.integers.theorems.2474761cf02407fcd54ac30926fa848232fdc9f10,proveit.numbers.numerals.decimals.theorems.d64204bc453bceba682a8e0d86bf6f914492a96d0,2235dee58a3fecd7484ea00ab222055c7e10c0220*,2235dee58a3fecd7484ea00ab222055c7e10c0230*]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_unique_rep_str_example_03 = 'Proof:instantiation:{proveit.common.09585084922504426caf1db2ff588a23a0932a960:proveit.numbers.number_sets.natural_numbers.common.8b7c321957f52ed3b05b36af612eeae4fa4783bc0,proveit.common.a9162d1c3cc0470c02e5daf414500903a7a419230:proveit.numbers.number_sets.integers.common.e6b4e90f9467053e055a4fd2f735c0bb79cb79300,proveit.common.a0d9d672aa5e272d907247690c152cc2c6daafb70:proveit.numbers.numerals.common.af4aab8a07465db063742696e006d04670f30cf10}[da20b31afeaf4605a1640e59551974583346a5110];[]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_colon_split = proof_unique_rep_str_example_02.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_colon_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_colon_split[0][0:5]=='Proof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_colon_split[0].split(\":\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_end_idx = semi_colon_split[0].split(\":\", 2)[2].find(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_dict = semi_colon_split[0].split(\":\", 2)[2][:dict_end_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_id = semi_colon_split[0].split(\":\", 2)[2][dict_end_idx+1:].strip(\"[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqs_str = semi_colon_split[1].strip(\"[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqs_str_list = reqs_str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database._parse_unique_rep(proof_unique_rep_str_example_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_unique_rep_str_example_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_unique_rep_str_example_03.split(\";\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'abc'.strip('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proof_unique_rep_str_example_03.split(\";\")[1].strip(\"][\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_empty_tuple = proof_unique_rep_str_example_03.split(\";\")[1].strip(\"[]\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strange_empty_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here\")\n",
    "for item in strange_empty_tuple:\n",
    "    print(item+\"<-something there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proveit import Database\n",
    "Database._parse_unique_rep(proof_unique_rep_str_example_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%end testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
